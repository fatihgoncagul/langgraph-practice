from typing import Annotated

from typing_extensions import TypedDict

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from tools import get_lab_results, get_patient_vitals
from tool_node import BasicToolNode
from langchain_openai import ChatOpenAI

class State(TypedDict):
    messages: Annotated[list, add_messages]

graph_builder = StateGraph(State)

llm = ChatOpenAI(
    base_url="http://localhost:1234/v1",
    api_key="lm-studio",  # herhangi bir ÅŸey olabilir, kontrol edilmiyor
     # LM Studio'daki tam model ismi
)
#llm = ChatOllama(model="llama3.1")

tools = [get_patient_vitals, get_lab_results]
llm_with_tools = llm.bind_tools(tools)

# ðŸ”§ Prompt Ã¶rneÄŸi iÃ§eren agent yÃ¶nlendirme formatÄ±
# ðŸ”§ Prompt Ã¶rneÄŸi iÃ§eren agent yÃ¶nlendirme formatÄ±
initial_messages = [
    {
        "role": "system",
        "content": """
Sen bir yapay zekÃ¢ saÄŸlÄ±k asistanÄ±sÄ±n. AÅŸaÄŸÄ±daki iki aracÄ± kullanabilirsin:

1. get_patient_vitals â€“ Belirli bir hastanÄ±n vital bilgilerini getirir.  
   Ã–rnek: Action Input: { "patient_id": 35 }

2. get_lab_results â€“ Belirli bir hastanÄ±n laboratuvar test sonuÃ§larÄ±nÄ± getirir.  
   Ã–rnek: Action Input: { "patient_id": 35 }

KullanÄ±cÄ± senden ÅŸunlarÄ± isteyebilir:
- Hasta bilgilerini istemek
- Laboratuvar sonuÃ§larÄ±nÄ± Ã¶ÄŸrenmek
- Ä°ki hasta arasÄ±nda kÄ±yaslama yapmak
- Ã–nce verileri almanÄ±, sonra yorumlamanÄ± istemek

AÅŸaÄŸÄ±daki kurallara dikkat et:
- Normal diyalog halinde olabilirsin.
- GerektiÄŸinde Ã¶nce uygun araÃ§larÄ± Ã§aÄŸÄ±r.
- Tool sonucu geldikten sonra soruyu yanÄ±tla.
- Tool'larÄ±n giriÅŸleri mutlaka JSON formatÄ±nda olmalÄ±.
- Gereksiz tool Ã§aÄŸrÄ±sÄ± yapma.

Tool KullanÄ±m FormatÄ±:
Thought: HastanÄ±n vital bilgilerine ihtiyacÄ±m var.
Action: get_patient_vitals
Action Input: { "patient_id": 35 }
Observation: ...
Thought: ArtÄ±k cevap verebilirim.
Final Answer: ...

Thought: HastanÄ±n laboratuvar bilgilerine ihtiyacÄ±m var.
Action: get_lab_results
Action Input: { "patient_id": 35 }
Observation: ...
Thought: ArtÄ±k cevap verebilirim.
Final Answer: ...
"""
    }
]




def chatbot(state: State):
    messages = state["messages"]

    messages = initial_messages + messages

    return {"messages": [llm_with_tools.invoke(messages)]}



# Add chatbot node
graph_builder.add_node("chatbot", chatbot)
graph_builder.add_edge(START, "chatbot")

# Tool node
tool_node = BasicToolNode(tools=tools)
graph_builder.add_node("tools", tool_node)

# Conditional routings
def route_tools(state: State):
    if isinstance(state, list):
        ai_message = state[-1]
    elif messages := state.get("messages", []):
        ai_message = messages[-1]
    else:
        raise ValueError(f"No messages found in input state to tool_edge: {state}")
    if hasattr(ai_message, "tool_calls") and len(ai_message.tool_calls) > 0:
        return "tools"
    return END

# Routing based on tool call presence
graph_builder.add_conditional_edges(
    "chatbot",
    route_tools,
    {"tools": "tools", END: END},
)

graph_builder.add_edge("tools", "chatbot")
graph = graph_builder.compile()
